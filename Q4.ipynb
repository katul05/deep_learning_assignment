{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import SVHN\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ],
      "metadata": {
        "id": "4hIeIpXGkInF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_lenet = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # Suitable for LeNet-5\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_set_lenet = SVHN(root='./data', split='train', download=True, transform=transform_lenet)\n",
        "test_set_lenet = SVHN(root='./data', split='test', download=True, transform=transform_lenet)\n",
        "\n",
        "train_loader_lenet = DataLoader(train_set_lenet, batch_size=64, shuffle=True)\n",
        "test_loader_lenet = DataLoader(test_set_lenet, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w7qPZU2kIkP",
        "outputId": "3a741a68-0a3c-4558-da51-fe08aa0a1f88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)  # 10 classes for SVHN\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "DKgx6WhgkISO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_lenet(model, train_loader, test_loader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):  # loop over the dataset multiple times\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_true.extend(labels.cpu().tolist())\n",
        "            y_pred.extend(predicted.cpu().tolist())\n",
        "\n",
        "    print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
        "    print(f'Classification Report:\\n{classification_report(y_true, y_pred)}')\n",
        "\n",
        "# Initialize and Train LeNet-5\n",
        "lenet_model = LeNet5()\n",
        "train_and_evaluate_lenet(lenet_model, train_loader_lenet, test_loader_lenet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CrzHH2WkIPV",
        "outputId": "9a9bb9e7-229e-4d35-815d-bfdd67b521df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.8926209406561206\n",
            "Epoch 2, Loss: 0.46027420497617344\n",
            "Epoch 3, Loss: 0.38863524000717564\n",
            "Epoch 4, Loss: 0.3473430911331198\n",
            "Epoch 5, Loss: 0.3184801222162736\n",
            "Epoch 6, Loss: 0.29405783008800324\n",
            "Epoch 7, Loss: 0.2752845263832521\n",
            "Epoch 8, Loss: 0.25926259597966766\n",
            "Epoch 9, Loss: 0.24106461627644743\n",
            "Epoch 10, Loss: 0.22749812419823162\n",
            "Accuracy: 0.8860248924400738\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.87      0.89      1744\n",
            "           1       0.90      0.95      0.93      5099\n",
            "           2       0.94      0.90      0.92      4149\n",
            "           3       0.81      0.87      0.84      2882\n",
            "           4       0.91      0.90      0.90      2523\n",
            "           5       0.94      0.81      0.87      2384\n",
            "           6       0.84      0.85      0.85      1977\n",
            "           7       0.92      0.88      0.90      2019\n",
            "           8       0.81      0.83      0.82      1660\n",
            "           9       0.81      0.87      0.84      1595\n",
            "\n",
            "    accuracy                           0.89     26032\n",
            "   macro avg       0.88      0.87      0.88     26032\n",
            "weighted avg       0.89      0.89      0.89     26032\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adapt_model_for_svhn(model):\n",
        "    if isinstance(model, torchvision.models.AlexNet) or isinstance(model, torchvision.models.VGG):\n",
        "        num_features = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Linear(num_features, 10)\n",
        "    elif isinstance(model, torchvision.models.ResNet):\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, 10)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ip4mA1bvkIND"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_pretrained = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images for pretrained models\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
        "])\n",
        "\n",
        "train_set_pretrained = SVHN(root='./data', split='train', download=True, transform=transform_pretrained)\n",
        "test_set_pretrained = SVHN(root='./data', split='test', download=True, transform=transform_pretrained)\n",
        "\n",
        "train_loader_pretrained = DataLoader(train_set_pretrained, batch_size=64, shuffle=True)\n",
        "test_loader_pretrained = DataLoader(test_set_pretrained, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyXyZfRzkIJy",
        "outputId": "1bd3e504-a10f-403c-d91b-34c17d852dc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/train_32x32.mat\n",
            "Using downloaded and verified file: ./data/test_32x32.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_pretrained(model, train_loader, test_loader):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):  # Loop over the dataset multiple times\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            y_true.extend(labels.cpu().tolist())\n",
        "            y_pred.extend(predicted.cpu().tolist())\n",
        "\n",
        "    print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
        "    print(f'Classification Report:\\n{classification_report(y_true, y_pred)}')\n"
      ],
      "metadata": {
        "id": "MQ4DRSCOkIGi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_models = {\n",
        "    'AlexNet': torchvision.models.alexnet(pretrained=True),\n",
        "    'VGG16': torchvision.models.vgg16(pretrained=True),\n",
        "    'ResNet18': torchvision.models.resnet18(pretrained=True),\n",
        "    'ResNet50': torchvision.models.resnet50(pretrained=True),\n",
        "    'ResNet101': torchvision.models.resnet101(pretrained=True)\n",
        "}\n",
        "\n",
        "for model_name, model in pretrained_models.items():\n",
        "    print(f\"\\nTraining and evaluating {model_name}...\")\n",
        "    model = adapt_model_for_svhn(model)\n",
        "    train_and_evaluate_pretrained(model, train_loader_pretrained, test_loader_pretrained)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCGQKqa4kZM_",
        "outputId": "a46cffc9-d0a0-4c14-97dd-e820c977082a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training and evaluating AlexNet...\n",
            "Epoch 1, Loss: 2.242017735352162\n",
            "Epoch 2, Loss: 2.238747703560575\n",
            "Epoch 3, Loss: 2.2380817681941405\n",
            "Epoch 4, Loss: 2.2377743031780795\n",
            "Epoch 5, Loss: 2.2374580102195907\n",
            "Epoch 6, Loss: 2.2373317720588117\n",
            "Epoch 7, Loss: 2.2372564109652324\n",
            "Epoch 8, Loss: 2.2371490428541425\n",
            "Epoch 9, Loss: 2.2370639342928555\n",
            "Epoch 10, Loss: 2.2370372289132865\n",
            "Accuracy: 0.1958743085433313\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1744\n",
            "           1       0.20      1.00      0.33      5099\n",
            "           2       0.00      0.00      0.00      4149\n",
            "           3       0.00      0.00      0.00      2882\n",
            "           4       0.00      0.00      0.00      2523\n",
            "           5       0.00      0.00      0.00      2384\n",
            "           6       0.00      0.00      0.00      1977\n",
            "           7       0.00      0.00      0.00      2019\n",
            "           8       0.00      0.00      0.00      1660\n",
            "           9       0.00      0.00      0.00      1595\n",
            "\n",
            "    accuracy                           0.20     26032\n",
            "   macro avg       0.02      0.10      0.03     26032\n",
            "weighted avg       0.04      0.20      0.06     26032\n",
            "\n",
            "\n",
            "Training and evaluating VGG16...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.2509748194415495\n",
            "Epoch 2, Loss: 2.2400775821968977\n",
            "Epoch 3, Loss: 2.2393393447826004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A6VVw0IskbAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}